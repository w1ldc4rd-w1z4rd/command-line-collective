<!DOCTYPE html>
<html lang="en">
    <head>
        
        <title>Command Line Collective</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>	
        <link href="https://fonts.googleapis.com/css2?family=Sono:wght@200..800&display=swap" rel="stylesheet">
        <link rel="icon" type="image/x-icon" href="/cfg/media/favicon.ico">
        <link rel="stylesheet" href="/cfg/css/normalize.css">
        <link rel="stylesheet" href="/cfg/css/html.css">
        <link rel="stylesheet" href="/cfg/css/custom.css">
    
    </head>
<body>
    	<main>
         
             <div style="margin-bottom: 15px;" id="image-header">
                <img src="/cfg/media/clc-logo2.png">
            </div>
            
            <p class="center">[ <a href="./">BACK...</a> ]</p>
            
    	    <h1>Prompting with Mistral 7B Model</h1>

<p>By: <a href="https://github.com/w1ldc4rd-w1z4rd">w1ldc4rd-w1z4rd</a></p>

<p>This guide provides insights on how to effectively prompt the Mistral 7B-Instruct model using structured tags for complex tasks and a more natural conversational style for simpler inquiries.</p>

<h3>Understanding Mistral's Prompt Structure</h3>

<p>Mistral prompts are typically structured using the <strong>[INST]</strong> tags for complex instructions. However, for simpler or more conversational interactions, tags are not necessary.</p>

<ul>
<li><p><strong>[INST] and [/INST] Tags</strong>:</p>

<ul>
<li><strong>Purpose</strong>: These tags are used to clearly define instructions within the prompt, indicating to the model the specific task to be performed.</li>
<li><strong>Usage</strong>: Enclose your command or instruction within these tags for tasks that require specific outputs or structured data.</li>
</ul></li>
<li><p><strong>Special Tokens &lt; s > and &lt; /s ></strong>:</p>

<ul>
<li><strong>Purpose</strong>: These tokens are used to mark the beginning and end of segments in multi-turn conversations.</li>
<li><strong>Usage</strong>: Use these in scenarios involving multiple interactions to maintain context and coherence.</li>
</ul></li>
</ul>

<h3>Crafting Effective Prompts</h3>

<h4>Single-Turn Prompts with Tags</h4>

<p><strong>Example</strong>:</p>

<p><code>
[INST] Generate a valid JSON object from the following data: name: John, lastname: Smith, address: #1 Samuel St. [/INST]
</code></p>

<p><strong>Curl</strong>:</p>

<p><code>
curl -sSL -N -X POST http://localhost:11434/api/generate \
-H "Content-Type: application/json" \
-d '{
"model": "Mistral",
"prompt": "[INST] Generate a valid JSON object from the following data: name: John, lastname: Smith, address: #1 Samuel St. [/INST]"
}'
</code></p>

<p><strong>Expected Output</strong>:</p>

<p><code>
{
    "name": "John",
    "lastname": "Smith",
    "address": "#1 Samuel St."
}
</code></p>

<h4>Multi-Turn Conversation Prompts with Tags</h4>

<p><strong>Example</strong>:</p>

<p><code>
&lt;s&gt;[INST] What is your favorite condiment? [/INST] "I like mustard, for its sharpness." &lt;/s&gt;  [INST] Why do you prefer it sharp? [/INST]
</code></p>

<p><strong>Curl</strong>:</p>

<p><code>
curl -sSL -N -X POST http://localhost:11434/api/generate \
-H "Content-Type: application/json" \
-d '{
    "model": "person",
    "prompt": "&lt;s&gt; [INST] What is your favorite condiment? [/INST] \"I like mustard, for its sharpness.\" &lt;/s&gt; [INST] Why do you prefer it sharp? [/INST]"
}'
</code></p>

<p><strong>Expected Output</strong>:</p>

<p><code>
"The sharpness adds a delightful kick that enhances flavors beautifully."
</code></p>

<h3>Flexibility in Prompting Mistral 7B-Instruct Model</h3>

<p>When you're using the Mistral 7B-Instruct model, remember that adding special tags like <strong>[INST]</strong>, <strong>&lt; s ></strong>, and <strong>&lt; /s ></strong>, or using structured prompts, is completely up to you. These tools are there to help when you need precise answers or want to keep a conversation flowing over multiple exchanges. They can really sharpen the model's responses and make sure everything stays on track.</p>

<p>However, if your questions are straightforward or if you're just having a casual chat, feel free to talk to the model in plain, natural language. There's no need to dress up your words in any special format.</p>

<p>This flexibility means you can interact with the model in whatever way works best for you at the moment, whether you're diving into the details of a complex topic or just enjoying a simple, friendly conversation.</p>

         
            <p id="bottom" class="center">
                üñ•Ô∏è <a target="_blank" href="https://www.meetup.com/command-line-collective">Meetup</a> - 
                üíæ <a target="_blank" href="https://github.com/w1ldc4rd-w1z4rd/command-line-collective">GitHub</a>
            </p>   
    	</main>
</body>
</html>
